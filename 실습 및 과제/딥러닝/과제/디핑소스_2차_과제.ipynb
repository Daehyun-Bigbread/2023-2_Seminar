{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ihobbang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ihobbang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ihobbang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/ihobbang/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 뉴스 기사 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 다운로드 및 텍스트 파싱\n",
    "url = 'https://finance.yahoo.com/news/exclusive-unilever-launches-bid-sell-133434534.html'\n",
    "\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()\n",
    "\n",
    "text = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Abigail Summerville\n",
      "\n",
      "(Reuters) - Unilever Plc has hired investment banks Morgan Stanley and Evercore Inc to sell a basket of non-core beauty and personal care brands that include Q-Tips and Impulse, reviving an effort it abandoned two years ago, according to people familiar with the matter.\n",
      "\n",
      "The revival of the sale process, which has not been previously reported, represents the first major move by Hein Schumacher, who took over as Unilever's chief executive in July with a focus to streamline its business as it grapples with inflation.\n",
      "\n",
      "The brand portfolio, known as Elida Beauty, also includes Caress, TIGI, Timotei, Monsavon, St. Ives, Zwitsal, Ponds, Brut, Moussel, Alberto Balsam and Matey. Elida generated about $760 million in revenue in 2022, according to the sources.\n",
      "\n",
      "Unilever worked with Credit Suisse in 2021 to divest Elida but pulled the process later that year, after cherry-picking of the brands for sale by other consumer companies led to offers that did not meet its valuation expectations, the sources said.\n",
      "\n",
      "Since then, Unilever has worked to make Elida an autonomous unit that could also appeal in its entirety to private equity firms, the sources added. Morgan Stanley and Evercore have now contacted several parties to gauge acquisition interest in Elida for what could be a multi-billion-dollar deal, according to the sources.\n",
      "\n",
      "The sources requested anonymity because the matter is confidential. Unilever, Morgan Stanley and Evercore declined to comment.\n",
      "\n",
      "The consumer goods industry has struggled with soaring costs for about two years, as everything from sunflower oil and shipping to packaging and grain has become more expensive. This has prompted Unilever, the maker of Dove soap and Ben & Jerry's ice cream, to review its portfolio of non-core assets it can sell to raise cash.\n",
      "\n",
      "Unilever beat underlying sales growth forecasts in the second quarter after raising prices to offset the higher costs. It has also considered selling some of its U.S. ice cream brands, including Klondike and Breyers.\n",
      "\n",
      "(Reporting by Abigail Summerville in New York; Additional reporting by Richa Naidu in London; Editing by Chizu Nomiyama)\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텍스트 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abigail: 2\n",
      "summerville: 2\n",
      "reuters: 1\n",
      "unilever: 7\n",
      "plc: 1\n",
      "hired: 1\n",
      "investment: 1\n",
      "banks: 1\n",
      "morgan: 3\n",
      "stanley: 3\n",
      "evercore: 3\n",
      "inc: 1\n",
      "sell: 2\n",
      "basket: 1\n",
      "beauty: 2\n",
      "personal: 1\n",
      "care: 1\n",
      "brands: 3\n",
      "include: 1\n",
      "impulse: 1\n",
      "reviving: 1\n",
      "effort: 1\n",
      "abandoned: 1\n",
      "two: 2\n",
      "years: 2\n",
      "ago: 1\n",
      "according: 3\n",
      "people: 1\n",
      "familiar: 1\n",
      "matter: 2\n",
      "revival: 1\n",
      "sale: 2\n",
      "process: 2\n",
      "previously: 1\n",
      "reported: 1\n",
      "represents: 1\n",
      "first: 1\n",
      "major: 1\n",
      "move: 1\n",
      "hein: 1\n",
      "schumacher: 1\n",
      "took: 1\n",
      "chief: 1\n",
      "executive: 1\n",
      "july: 1\n",
      "focus: 1\n",
      "streamline: 1\n",
      "business: 1\n",
      "grapples: 1\n",
      "inflation: 1\n",
      "brand: 1\n",
      "portfolio: 2\n",
      "known: 1\n",
      "elida: 5\n",
      "also: 3\n",
      "includes: 1\n",
      "caress: 1\n",
      "tigi: 1\n",
      "timotei: 1\n",
      "monsavon: 1\n",
      "ives: 1\n",
      "zwitsal: 1\n",
      "ponds: 1\n",
      "brut: 1\n",
      "moussel: 1\n",
      "alberto: 1\n",
      "balsam: 1\n",
      "matey: 1\n",
      "generated: 1\n",
      "760: 1\n",
      "million: 1\n",
      "revenue: 1\n",
      "2022: 1\n",
      "sources: 5\n",
      "worked: 2\n",
      "credit: 1\n",
      "suisse: 1\n",
      "2021: 1\n",
      "divest: 1\n",
      "pulled: 1\n",
      "later: 1\n",
      "year: 1\n",
      "consumer: 2\n",
      "companies: 1\n",
      "led: 1\n",
      "offers: 1\n",
      "meet: 1\n",
      "valuation: 1\n",
      "expectations: 1\n",
      "said: 1\n",
      "since: 1\n",
      "make: 1\n",
      "autonomous: 1\n",
      "unit: 1\n",
      "could: 2\n",
      "appeal: 1\n",
      "entirety: 1\n",
      "private: 1\n",
      "equity: 1\n",
      "firms: 1\n",
      "added: 1\n",
      "contacted: 1\n",
      "several: 1\n",
      "parties: 1\n",
      "gauge: 1\n",
      "acquisition: 1\n",
      "interest: 1\n",
      "deal: 1\n",
      "requested: 1\n",
      "anonymity: 1\n",
      "confidential: 1\n",
      "declined: 1\n",
      "comment: 1\n",
      "goods: 1\n",
      "industry: 1\n",
      "struggled: 1\n",
      "soaring: 1\n",
      "costs: 2\n",
      "everything: 1\n",
      "sunflower: 1\n",
      "oil: 1\n",
      "shipping: 1\n",
      "packaging: 1\n",
      "grain: 1\n",
      "become: 1\n",
      "expensive: 1\n",
      "prompted: 1\n",
      "maker: 1\n",
      "dove: 1\n",
      "soap: 1\n",
      "ben: 1\n",
      "jerry: 1\n",
      "ice: 2\n",
      "cream: 2\n",
      "review: 1\n",
      "assets: 1\n",
      "raise: 1\n",
      "cash: 1\n",
      "beat: 1\n",
      "underlying: 1\n",
      "sales: 1\n",
      "growth: 1\n",
      "forecasts: 1\n",
      "second: 1\n",
      "quarter: 1\n",
      "raising: 1\n",
      "prices: 1\n",
      "offset: 1\n",
      "higher: 1\n",
      "considered: 1\n",
      "selling: 1\n",
      "including: 1\n",
      "klondike: 1\n",
      "breyers: 1\n",
      "reporting: 2\n",
      "new: 1\n",
      "york: 1\n",
      "additional: 1\n",
      "richa: 1\n",
      "naidu: 1\n",
      "london: 1\n",
      "editing: 1\n",
      "chizu: 1\n",
      "nomiyama: 1\n"
     ]
    }
   ],
   "source": [
    "# 단어 토큰화\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# 불용어(stopwords) 제거\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "# 각 단어의 빈도 계산\n",
    "freq_dist = FreqDist(filtered_tokens)\n",
    "\n",
    "for word, frequency in freq_dist.items():\n",
    "    print(f'{word}: {frequency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 상위 빈도 10개 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unilever: 7\n",
      "elida: 5\n",
      "sources: 5\n",
      "morgan: 3\n",
      "stanley: 3\n",
      "evercore: 3\n",
      "brands: 3\n",
      "according: 3\n",
      "also: 3\n",
      "abigail: 2\n"
     ]
    }
   ],
   "source": [
    "# 빈도가 가장 높은 상위 단어 출력 (예: 상위 10개)\n",
    "most_common_words = freq_dist.most_common(10)\n",
    "\n",
    "for word, frequency in most_common_words:\n",
    "    print(f'{word}: {frequency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 뉴스 기사 단어 수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사의 길이 (단어 수): 390\n"
     ]
    }
   ],
   "source": [
    "word_count = len(words)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"뉴스 기사의 길이 (단어 수): {word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 문장의 평균 길이 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 평균 길이: 27.857142857142858\n"
     ]
    }
   ],
   "source": [
    "# 문장 토큰화\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# 각 문장의 길이 측정\n",
    "sentence_lengths = [len(word_tokenize(sentence)) for sentence in sentences]\n",
    "\n",
    "# 평균 문장 길이 계산\n",
    "average_sentence_length = sum(sentence_lengths) / len(sentence_lengths)\n",
    "\n",
    "print(f\"문장의 평균 길이: {average_sentence_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 긍부정 단어 빈도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 빈도: 7\n",
      "부정적인 단어 빈도: 2\n"
     ]
    }
   ],
   "source": [
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "# 긍정적인 단어와 부정적인 단어의 빈도 계산\n",
    "positive_word_count = sum(1 for word in words if word in positive_words)\n",
    "negative_word_count = sum(1 for word in words if word in negative_words)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"긍정적인 단어 빈도: {positive_word_count}\")\n",
    "print(f\"부정적인 단어 빈도: {negative_word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 최고빈도 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unilever: 7\n"
     ]
    }
   ],
   "source": [
    "# 텍스트에서 명사 추출\n",
    "def extract_nouns(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    nouns = [word for word, tag in tagged if tag in ['NN', 'NNS', 'NNP', 'NNPS']]  # 명사 태그를 포함하는 단어 추출\n",
    "    return nouns\n",
    "\n",
    "nouns = extract_nouns(text)\n",
    "\n",
    "# 명사 빈도 계산\n",
    "noun_freq = Counter(nouns)\n",
    "\n",
    "# 가장 많이 등장하는 명사 출력 \n",
    "most_common_nouns = noun_freq.most_common(1)\n",
    "\n",
    "for noun, freq in most_common_nouns:\n",
    "    print(f'{noun}: {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 텍스트 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Unilever has hired investment banks Morgan Stanley and Evercore Inc to sell a basket of non-core beauty and personal care brands. The revival of the sale process represents the first major move by Hein Schumacher, who took over as Unilever's chief executive.\"}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(text, max_length=100, min_length=30, do_sample=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
